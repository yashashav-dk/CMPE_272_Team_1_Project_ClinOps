version: '3.8'

services:
  # Main Application (Alternative to PM2)
  # Uncomment to run the app in Docker instead of PM2
  # app:
  #   build:
  #     context: ./clin-ops
  #     dockerfile: Dockerfile.production
  #   ports:
  #     - "3000:3000"
  #   env_file:
  #     - ./clin-ops/.env
  #   restart: unless-stopped
  #   depends_on:
  #     - prometheus
  #     - grafana
  #     - loki
  #     - tempo
  #   networks:
  #     - observability
  #   labels:
  #     - "compose_service=app"

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:v2.53.2
    container_name: clinops-prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --web.external-url=/prometheus/
      - --web.route-prefix=/
    volumes:
      - ./observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    restart: unless-stopped
    networks:
      - observability

  # AlertManager - Alert Management
  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: clinops-alertmanager
    command:
      - --config.file=/etc/alertmanager/alertmanager.yml
      - --web.external-url=/alertmanager/
      - --web.route-prefix=/
    volumes:
      - ./observability/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager
    ports:
      - "9093:9093"
    restart: unless-stopped
    networks:
      - observability

  # Grafana - Visualization Dashboard
  grafana:
    image: grafana/grafana:11.4.0
    container_name: clinops-grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GF_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_ADMIN_PASSWORD:-admin}
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s:%(http_port)s/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
    volumes:
      - grafana-data:/var/lib/grafana
      - ./observability/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./observability/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
    ports:
      - "3001:3000"
    restart: unless-stopped
    depends_on:
      - prometheus
      - loki
      - tempo
    networks:
      - observability

  # Loki - Log Aggregation
  loki:
    image: grafana/loki:2.9.6
    container_name: clinops-loki
    command: ["-config.file=/etc/loki/config/config.yml"]
    volumes:
      - loki-data:/loki
      - ./observability/loki-config.yml:/etc/loki/config/config.yml:ro
    ports:
      - "3100:3100"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3100/ready"]
      interval: 10s
      timeout: 3s
      retries: 10
    networks:
      - observability

  # Promtail - Log Shipper
  promtail:
    image: grafana/promtail:2.9.6
    container_name: clinops-promtail
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/log:/var/log:ro
      - ./observability/promtail-config-clean.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml
    restart: unless-stopped
    depends_on:
      - loki
    networks:
      - observability

  # Tempo - Distributed Tracing
  tempo:
    image: grafana/tempo:2.5.0
    container_name: clinops-tempo
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ./observability/tempo-config.yml:/etc/tempo.yaml:ro
      - tempo-data:/var/tempo
    ports:
      - "3200:3200"  # tempo
      - "4317:4317"  # otlp grpc
      - "4318:4318"  # otlp http
    restart: unless-stopped
    networks:
      - observability

volumes:
  prometheus-data:
  alertmanager-data:
  grafana-data:
  loki-data:
  tempo-data:

networks:
  observability:
    driver: bridge
